<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Jaivanti Dhokey | Anomaly Detection</title>
  <meta name="description" content="Personal Website">
  <link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon">
  
  <!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

 <!-- Styles -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/projects/anomaly/ind.html">
  

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
  </head>
  <body>

 <body class="fixed-top-nav ">

    
    
    
    <!-- Header -->

    <header>
  <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
       <a class="navbar-brand title font-weight-lighter" href="/aerial/index.html">
        <span class="font-weight-bold">Jaivanti</span>  Dhokey
      </a>
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
            <!--    <span class="sr-only">(current)</span>  -->
              
            </a>
          </li>
          <!-- Other pages -->
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://drive.google.com/file/d/1Ldqv0-L_dGTgaCRe93mUkp0lyLAUQhNt/view">
                CV
         
              </a>
          </li>      
          
          
          
          
            <li class="nav-item ">
              <a class="nav-link" href="/proj1.html">
                Project
                
              </a>
          </li>   
          
           <li class="nav-item ">
              <a class="nav-link" href="/blog.html">
                Blogs
                
              </a>
          </li>
          
          <li class="nav-item">
            <a class="nav-link" href="/media/web%20dev/index2.html">
                Media
                
              </a>
          </li>
          
          
     <!--   <button style="border:none; background:none;" onclick="modeSwitcher()"><a class="sr-only" id="theme-toggle"></a><i id="icon-toggle" class="fas fa-moon"></i></button>-->
          
          
        </ul>
      </div>
    </div>
  </nav>
<!-- Scrolling Progress Bar <progress id="progress" value="0">  <div class="progress-container">    <span class="progress-bar"></span> </div> </progress> -->
</header> 
   
   <!-- Content -->
   
<div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span>Anomaly Detection Using Standard and Poor's 500 Index</span> 
    </h1>
    <p class="desc"><h4>Detecting anomalies around S&P-500 using LSTM AutoEncoders.</h4></p>
  </header>

  <p><br />
This is implementation of Anomaly Detection using Time series data in Keras API. Specifically, designing and training and 
    LSTM autoencoder using the Keras API with Tensorflow 2 as the backend to detect anomalies (sudden price changes) in the S&P 500 index.
     The complete code for the project can be found <a href="https://github.com/jaivanti/Anomaly-Detection-on-S-P-500">here</a>.</p>

<h4 id="data-set-summary--exploration"><strong>Data Set Summary &amp; Exploration</strong></h4>
<hr/>
<p>We have used S&P 500, or simply the S&P, as the time series data which is a, stock market index that measures the stock performance of 500 large companies listed on stock exchanges in the United States. 
  It is one of the most commonly followed equity indices. Anomaly Detection would be used to measure abrupt changes in the stock prices of S&P 500 newplot. 
  The S&P 500 index data is in the form of a csv file. The data is further processed into train and test data</p>
  <ul>
  <li>The size of training set is 6523.</li>
  <li>The size of test set is 1639.</li>
  <li>The number of unique classes/labels in the data set is 2 ie. date and close.</li>
</ul>
  <p>The dataset is in csv format with date and close price from 1986 to 2018.</p>
  <p>Here is the exploratory visualisation of the dataset. Here is the graph of dataset.</p>
  <p align="center">
  <img src="/assets/img/newplot.png" width="600" height="300"/>
  </p>
  <h4 id="data-preprocessing">Data preprocessing</h4>
  <p>The csv data was further processed into training data and test data using pandas. Here 80% of dataframe will be used for training and 
    20% will be used for testing. We use <code>iloc</code> method to specify slicing by index. </p>
  <p align="center">
  <img src="/projects/anomaly/dataprocess.png" width="600" height="300"/>
  </p>
  <p>The target vector is standarized by removing the mean and scaling it to the unit variance
    using <code>StandardScaler</code> function from <code>sklearn.preprocessing</code></p>   
  <p>The Data vectors are then reshaped in the form <code>n(samples)</code>
    by <code>n(time_steps)</code> by <code>n(features)</code> in line with Time-Series modelling.</p>
  <h4 id="Create Train and Test Data">Create Test and Train Data</h4>
  <p>Segregate the data in a sliding-window of 30 days per partition.Then, Save each
    partition of 30 days as an element in the training vector. Add the following day's closing value as a corresponding element in the target vector.</p>
 <h4 id="model-architecture"><strong>Model Architecture &amp; Training</strong></h4>
<hr/> 
  <p>Model used for anomaly detection is made using LSTM architecture and then the autoencoder is trained. The entire process is further explained below. </p>
  <h4 id="data-preprocessing">LSTM Architecture Autoencoder</h4>
  <p>First let's understand the meaning of LSTM architecture. </p>
  <p>LSTM stands for Long Short-term Memory, which is also an artificial neural network similar to Recurrent Neural Network(RNN). It processes the datas passing on the information as it propagates. It has a cell, allows the neural network to keep or forget the information. </p>
  <p>For this, an LSTM Autoencoder network is built which visualises the architecture and data flow. So here’s how anomalies using an autoencoder is gonna get detected.
  First, the data is trained with no anomalies and then take the new data point and try to reconstruct that using an autoencoder. 
    If the reconstruction error for the new dataset is above some threshold, then it's going to label that example/data point as an anomaly.</p>
    <p align="center">
  <img src="/projects/anomaly/lstmmodel.png" width="600" height="300"/>
  </p>
  <p align="center">
  <img src="/projects/anomaly/lstmcode.png" width="600" height="300"/>
  </p>
  <p>In the above codes, X_train array i.e. (6523, 30, 1) is assigned. While building the LSTM architecture, Sequential model from keras API is used.
  The sample data is 1% which is 2D array and is passed to LSTM as input. The output of the layer is going to be a feature vector of input data.
  One LSTM layer is created with the number of cells to be 128. Input shape is equal to no. of time_stpes divided by no. of features. Then,
    the Dropout regularization is added to 0.2. Since the network is LSTM, we need to duplicate this vector using RepeatVector. 
    It’s purpose is to just replicate the feature vector from the output of LSTM layer 3o times. The encoder is done here.
</p>
  <p>In decoder layer, TimeDistributed function creates a dense layer with number of nodes equal to the number of features. And the model is compiled finally using adam optimizer function which is gradient descent optimizer.The 
  model summary is shown above.</p>
  <h4 id="data-preprocessing">Autoencoder Training</h4>
  <p>Keras Callback is created using early stopping so that the number of epochs are not needed to hard code. If the network doesn’t improve for 3 consecutive epochs,i.e. validation loss is not decreased we are going to stop our training process.
    That is the meaning of patience. And now let’s fit the model to our calling data. No. of epochs is set to high as higher the epochs, more the accuracy of training. 10 % of the data is set for validation. And then the callback is done using <code>es</code> i.e. 
    EarlyStopping.</p>
<p align="center">
  <img src="/projects/anomaly/auto.png" width="600" height="300"/>
  </p>
  <h4 id="data-preprocessing">Plot Metrics and Evaluate the Model</h4>
  <p>Now the matrix that is training loss and validation loss is plotted using matplotlib. In the plot, validation loss is consistently found to be lower than training loss that means the training data due to the high dropout value 
    we used So you can change the hyperparameters in 5th step to optimize the model.</p>
  <p align="center">
  <img src="/projects/anomaly/metrics.png" width="500" height="200"/>
  </p>
  <p align="center">
  <img src="/projects/anomaly/index.png" width="600" height="300"/>
  </p>
  </body>
        </html> 
